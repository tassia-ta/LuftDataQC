{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb46c998-01d9-4334-816b-c6611e527306",
   "metadata": {},
   "source": [
    "| [![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](../LICENSE) | [![Python](https://img.shields.io/badge/Python-3.10+-black.svg)](https://www.python.org/) | [![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-red.svg)](https://jupyter.org/) | [![SQLite](https://img.shields.io/badge/Database-SQLite-darkblue.svg)](https://www.sqlite.org/index.html) | [![Pandas](https://img.shields.io/badge/Data-Pandas-purple.svg)](https://pandas.pydata.org/) | [![Plotly](https://img.shields.io/badge/Plots-Plotly-darkorange.svg)](https://plotly.com/python/) | [![Requests](https://img.shields.io/badge/HTTP-Requests-darkred.svg)](https://docs.python-requests.org/) | [![JSON](https://img.shields.io/badge/Data-JSON-grey.svg)](https://www.json.org/) | [![Pathlib](https://img.shields.io/badge/FS-Pathlib-black.svg)](https://docs.python.org/3/library/pathlib.html) |\n",
    "|---|---|---|---|---|---|---|---|---|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873ff9b8-724c-46fb-8ec5-aff19b5670bb",
   "metadata": {},
   "source": [
    "## Notebook 1 - Data Collection, Inspection and Storage  \n",
    "\n",
    "**LuftDataQC: PM2.5 raw data from NILU API (2023)**  \n",
    "Source: [https://api.nilu.no](https://api.nilu.no)  \n",
    "\n",
    "---\n",
    "\n",
    "### EN: Project overview  \n",
    "**Goal:** Fetch 2023 hourly PM2.5 data from NILU for all available stations in Norway, inspect per-station coverage, and persist raw data.  \n",
    "**Method:** HTTP requests ‚Üí JSON ‚Üí pandas ‚Üí SQLite.  \n",
    "**Tools:** Python (`requests`, `json`, `pathlib`, `pandas`, `sqlite3`, `plotly`)  \n",
    "\n",
    "### NO: Prosjektoversikt  \n",
    "**M√•l:** Hente timesvise PM2.5-data (2023) fra NILU for alle tilgjengelige stasjoner i Norge, inspisere dekning per stasjon og lagre r√•data.  \n",
    "**Metode:** HTTP-foresp√∏rsler ‚Üí JSON ‚Üí pandas ‚Üí SQLite.  \n",
    "**Verkt√∏y:** Python (`requests`, `json`, `pathlib`, `pandas`, `sqlite3`, `plotly`)  \n",
    "\n",
    "---\n",
    "\n",
    "### Reproducibility - quick reference | Reproduserbarhet - hurtigoversikt  \n",
    "\n",
    "**Outputs (this notebook):**  \n",
    "- `data/raw/nilu_pm25_<station>_2023.json` *(one file per station | √©n fil per stasjon)*  \n",
    "- `data/processed/pm25_2023.sqlite` *(SQLite database | SQLite-database)*  \n",
    "- `results/pm25_station_coverage_2023.html` *(interactive coverage chart | interaktivt dekningsdiagram)*  \n",
    "- `results/pm25_station_coverage_2023.png` *(static export via kaleido | statisk eksport via kaleido)*  \n",
    "**Parameters (this notebook):**  \n",
    "- **Year** = 2023  \n",
    "- **Pollutant** = PM2.5  \n",
    "- Station count and coverage are dynamically computed, no hard-coded values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b10e17d-7595-45b8-af20-f14fbe64b58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (EN) Reproducibility parameters and paths\n",
    "# (NO) Reproduserbarhetsparametere og stier\n",
    "\n",
    "YEAR = \"2023\"\n",
    "COMPONENT = \"PM2.5\"\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Define project paths (relative to /notebooks)\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "RAW_DIR = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "PROCESSED_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "RESULT_DIR = PROJECT_ROOT / \"results\"\n",
    "\n",
    "# Ensure output folders exist (run once)\n",
    "for folder in [RAW_DIR, PROCESSED_DIR, RESULT_DIR]:\n",
    "    folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Standard file paths for outputs\n",
    "COVERAGE_HTML = RESULT_DIR / f\"pm25_station_coverage_{YEAR}.html\"\n",
    "COVERAGE_PNG  = RESULT_DIR / f\"pm25_station_coverage_{YEAR}.png\"\n",
    "DB_PATH       = PROCESSED_DIR / f\"pm25_{YEAR}.sqlite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0232b629-b394-454c-ba6d-43abbd3fdeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (EN) Import required libraries and verify data/result folders\n",
    "# (NO) Importerer n√∏dvendige biblioteker og bekrefter mapper for data/resultater\n",
    "\n",
    "# Standard library\n",
    "import sqlite3\n",
    "\n",
    "# Third-party libraries\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Confirm that folders exist\n",
    "print(f\"  ‚Ä¢ RAW_DIR exists:        {RAW_DIR.exists()}\")\n",
    "print(f\"  ‚Ä¢ PROCESSED_DIR exists:  {PROCESSED_DIR.exists()}\")\n",
    "print(f\"  ‚Ä¢ RESULT_DIR exists:     {RESULT_DIR.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d40ffe-5c54-41d9-a45a-57c40d4fd84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EN: Fetch PM2.5 data for all stations in 2023 and save each file as JSON\n",
    "# NO: Hent PM2.5 data for alle stasjoner i 2023 og lagre hver fil som JSON\n",
    "\n",
    "# Define the date range for data retrieval\n",
    "from_date = \"2023-01-01\"\n",
    "to_date   = \"2023-12-31\"\n",
    "\n",
    "# Build the API URL for NILU's historical air quality data\n",
    "url = f\"https://api.nilu.no/aq/historical/{from_date}/{to_date}/all\"\n",
    "print(f\"Requesting data from NILU API:\\n‚Üí {url}\")\n",
    "\n",
    "# If files already exist in RAW_DIR, skip downloading\n",
    "if not any(RAW_DIR.glob(f\"nilu_pm25_*_{from_date[:4]}.json\")):\n",
    "    try:\n",
    "        # Send GET request with timeout for connection and read\n",
    "        response = requests.get(url, timeout=(10, 60))\n",
    "\n",
    "        # Check if the response is successful (HTTP 200)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to fetch data (HTTP {response.status_code}). / Kunne ikke hente data (HTTP {response.status_code}).\")\n",
    "        else:\n",
    "            # Convert JSON response to Python list of dictionaries\n",
    "            all_data = response.json()\n",
    "\n",
    "            # Filter only PM2.5 measurements from the full dataset\n",
    "            pm25_data = [entry for entry in all_data if entry.get(\"component\") == \"PM2.5\"]\n",
    "            print(f\"Download complete ‚Äî found {len(pm25_data)} PM2.5 records. / Nedlasting fullf√∏rt ‚Äî fant {len(pm25_data)} PM2.5-observasjoner.\")\n",
    "\n",
    "            # Group measurements by station name\n",
    "            station_groups = {}\n",
    "            for entry in pm25_data:\n",
    "                station = entry.get(\"station\")\n",
    "                if station:\n",
    "                    station_groups.setdefault(station, []).append(entry)\n",
    "\n",
    "            print(f\"Stations with data: {len(station_groups)}\")\n",
    "\n",
    "            # Save one JSON file per station to the RAW_DIR folder\n",
    "            for station, records in station_groups.items():\n",
    "                # Replace problematic characters in station name for file naming\n",
    "                clean_station = station.replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "                filename = f\"nilu_pm25_{clean_station}_{from_date[:4]}.json\"\n",
    "                file_path = RAW_DIR / filename\n",
    "\n",
    "                try:\n",
    "                    # Write station-specific data to JSON file with UTF-8 encoding\n",
    "                    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                        json.dump(records, f, ensure_ascii=False, indent=2)\n",
    "                    print(f\"Saved: {file_path.name}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    # Catch and report any file writing error\n",
    "                    print(f\"Failed to save {filename}: {e} / Kunne ikke lagre {filename}: {e}\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"HTTP request failed: {e} / HTTP-foresp√∏rsel feilet: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"Skipping download ‚Äî file already exists in data/raw. / Hopper over nedlasting ‚Äî filen finnes allerede i data/raw.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340baf6a-f6b3-4943-8d06-fd778c5d5e7e",
   "metadata": {},
   "source": [
    "**(EN)** Found 58 JSON files with PM2.5 data, each corresponding to one NILU monitoring station in Norway for the year 2023.  All PM2.5 station datasets for 2023 were saved as separate JSON files in `data/raw/`.  \n",
    "Each file name follows the pattern `nilu_pm25_<station>_2023.json`, ensuring easy station-level access.  \n",
    "\n",
    "**(NO)** Fant 58 JSON-filer med PM2.5-data, hver tilsvarende √©n NILU m√•lestasjon i Norge for √•ret 2023. Alle PM2.5-stasjonsdatasett for 2023 ble lagret som separate JSON-filer i `data/raw/`.  \n",
    "Hvert filnavn f√∏lger m√∏nsteret `nilu_pm25_<station>_2023.json`, noe som sikrer enkel tilgang p√• stasjonsniv√•.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2308a616-8a2d-47ed-bd8c-8d1b706b04eb",
   "metadata": {},
   "source": [
    "### Quality Assurance (QA): Data Integrity Checks | Kvalitetssikring (KS): Kontroll av dataintegritet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3565009-5ed3-45db-b2a7-04dac1c6c945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (EN) Check for empty or invalid PM2.5 JSON files after saving\n",
    "# (NO) Sjekk for tomme eller ugyldige PM2.5-JSON-filer etter lagring\n",
    "\n",
    "pm25_files = list(RAW_DIR.glob(\"nilu_pm25_*.json\"))\n",
    "empty_files = []\n",
    "\n",
    "for file_path in pm25_files:\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "            if not data:\n",
    "                empty_files.append(file_path.name)\n",
    "    except Exception as e:\n",
    "        print(f\" Error reading {file_path.name}: {e}\")\n",
    "        empty_files.append(file_path.name)\n",
    "\n",
    "# Result summary\n",
    "if empty_files:\n",
    "    print(f\" Found {len(empty_files)} empty or unreadable files:\")\n",
    "    for fname in empty_files:\n",
    "        print(\"-\", fname)\n",
    "else:\n",
    "    print(\" No empty PM2.5 files found. All files contain data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3e5612-a303-4eb9-a10e-827dc3427819",
   "metadata": {},
   "source": [
    "**(EN)** Data integrity check passed ‚Äî all downloaded PM2.5 JSON files contain valid measurement records.  \n",
    "**(NO)** Dataintegritetssjekk best√•tt ‚Äî alle nedlastede PM2.5-JSON-filer inneholder gyldige m√•leresultater.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5a72d8-fd2f-4eeb-bda9-ac0ab6a119f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (EN) Recursively search for all PM2.5 JSON files in the 'data' folder\n",
    "# (NO) S√∏k rekursivt etter alle PM2.5 JSON-filer i 'data'-mappen\n",
    "\n",
    "raw_dir = RAW_DIR\n",
    "pm25_files = list(raw_dir.glob(\"nilu_pm25_*.json\"))\n",
    "\n",
    "# show the first 10 files \n",
    "print(f\"Found {len(pm25_files)} PM2.5 files.\")\n",
    "for file in pm25_files[:10]:  \n",
    "    print(\"-\", file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14028cf4-b9ad-4408-aa3b-fcb16dae0667",
   "metadata": {},
   "source": [
    "**(EN)** Located all PM2.5 JSON files for 2023 in the `data/raw` folder - 58 files in total.         \n",
    "**(NO)** Fant alle PM2.5-JSON-filer for 2023 i mappen `data/raw` - totalt 58 filer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46fdbe6-5409-4203-a25e-92747f0cb92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (EN) Inspect one JSON file to check if the structure is as expected\n",
    "# (NO) Inspiser en JSON-fil for √• kontrollere at strukturen er som forventet\n",
    "\n",
    "for file_path in pm25_files[:1]:  # Only the first file\n",
    "    print(f\"\\nInspecting: {file_path.name}\")\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "            print(f\"Type: {type(data)}, Length: {len(data)}\")\n",
    "\n",
    "            if data:\n",
    "                print(f\"First record keys: {list(data[0].keys())}\")\n",
    "                print(f\"Length of 'values': {len(data[0].get('values', []))}\")\n",
    "            else:\n",
    "                print(\" File is empty (zero-length list).\")\n",
    "    except Exception as e:\n",
    "        print(f\" Error reading file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebd73ff-2cee-47de-ace1-b5e551c287ae",
   "metadata": {},
   "source": [
    "**(EN)** The PM2.5 JSON files are structured as a list containing one dictionary per station.  \n",
    "Each dictionary stores metadata (e.g., `station`, `component`, `unit`) and the`\"values\"`field with hourly measurements for the year.  \n",
    "**(NO)** PM2.5-JSON-filene er strukturert som en liste som inneholder √©n ordbok per stasjon.  \n",
    "Hver ordbok inneholder metadata (f.eks. station, component, unit) og \"values\"-feltet med de timesvise m√•lingene for √•ret.\n",
    "\n",
    "Inspecting: `nilu_pm25_Vahl_skole_2023.json`  \n",
    "Type: `<class 'list'>`, Lengde: `1`  \n",
    "First record keys: `['id', 'zone', 'municipality', 'area', 'station', 'type', 'eoi', 'component', 'latitude', 'longitude', 'timestep', 'isVisible', 'unit', 'values']`  \n",
    "Length of `\"values\"`: `8393`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67b6211-4dfa-487b-8729-51a262c09b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (EN) Check structure and metadata: station, component, unit, and number of values\n",
    "# (NO) Sjekk struktur og metadata: stasjon, komponent, enhet og antall m√•linger\n",
    "\n",
    "for file_path in RAW_DIR.glob(\"nilu_pm25_*.json\"):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    if not isinstance(data, list) or len(data) < 1:\n",
    "        print(f\" Unexpected structure in: {file_path.name}\")\n",
    "        continue\n",
    "\n",
    "    for record in data:\n",
    "        station = record.get(\"station\", \"unknown\")\n",
    "        component = record.get(\"component\", \"unknown\")\n",
    "        unit = record.get(\"unit\", \"unknown\")\n",
    "        values = record.get(\"values\", [])\n",
    "        num_values = len(values)\n",
    "\n",
    "        print(f\"{file_path.name}\")\n",
    "        print(f\"   Station: {station} | Component: {component} | Unit: {unit} | # values: {num_values}\\n\")\n",
    "        break  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a840c7-86ce-4c6d-b01e-a1f6d20b34b4",
   "metadata": {},
   "source": [
    "##### **(EN)**  File structure\n",
    "\n",
    "The PM2.5 files are JSON lists, each containing a single dictionary for one monitoring station. Each dictionary contains:\n",
    "\n",
    "* **Station name** (e.g., `\"Vahl skole\"`)\n",
    "* **Component** (e.g., `\"PM2.5 ¬µg/m¬≥\"`)\n",
    "* **Metadata** (location, type, timestep, unit, coordinates)\n",
    "* **Values** ‚Äî a list of hourly measurements for the selected year\n",
    "\n",
    "##### **(NO)**  Filstruktur\n",
    "\n",
    "PM2.5-filene er JSON-lister som inneholder √©n ordbok for √©n m√•lestasjon. Hver ordbok inkluderer:\n",
    "\n",
    "* **M√•lestasjon** (f.eks. `\"Vahl skole\"`)\n",
    "* **Komponent** (f.eks. `\"PM2.5 ¬µg/m¬≥\"`)\n",
    "* **Metadata** (lokasjon, type, tidssteg, enhet, koordinater)\n",
    "* **Values** ‚Äî en liste med timesvise m√•linger for det valgte √•ret\n",
    "\n",
    "**Example keys:**\n",
    "`['id', 'zone', 'municipality', 'area', 'station', 'type', 'eoi', 'component', 'latitude', 'longitude', 'timestep', 'isVisible', 'unit', 'values']`\n",
    "\n",
    "**Example file:** `nilu_pm25_Olav_V_gate_2023.json`\n",
    "Station: **Olav V gate** | Component: **PM2.5** | Unit: **¬µg/m¬≥** | Number of hourly values: **8,718**\n",
    "\n",
    "_____\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361e2a46-4be7-4714-8759-cd33c6bb835c",
   "metadata": {},
   "source": [
    "### Station Coverage Summary | Oversikt over stasjonsdekning\n",
    "\n",
    "**(EN)** The number of hourly PM2.5 records per station (2023) was counted to identify stations with sufficient coverage for further analysis.\n",
    "\n",
    "**(NO)**  Antall timesvise PM2.5-m√•linger per stasjon (2023) ble telt for √• identifisere stasjoner med tilstrekkelig datadekning for videre analyse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce594179-4608-4619-8a36-2fe01b80a151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (EN) Load all PM2.5 records from JSON files in the raw data folder\n",
    "# (NO) Last inn alle PM2.5-data fra JSON-filer i mappen med r√•data\n",
    "\n",
    "pm25_files = list(RAW_DIR.glob(\"nilu_pm25_*.json\"))\n",
    "\n",
    "if not pm25_files:\n",
    "    print(\" No PM2.5 files found in RAW_DIR. Please run the data download step first.\")\n",
    "else:\n",
    "    pm25_data = []\n",
    "    for file in pm25_files:\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            records = json.load(f)\n",
    "            pm25_data.extend(records)\n",
    "    print(f\" Loaded {len(pm25_data)} PM2.5 records from {len(pm25_files)} files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08635bb-c344-40bc-a00c-24ab8e4e42f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (EN) Count the number of hourly PM2.5 values per station and display the top 10  \n",
    "# (NO) Tell antall PM2.5-timer per stasjon og vis de 10 beste\n",
    "\n",
    "# List all JSON files that start with 'nilu_pm25_'\n",
    "pm25_files = list(RAW_DIR.glob(\"nilu_pm25_*.json\"))\n",
    "\n",
    "station_counts = []\n",
    "\n",
    "# Loop through each file and extract station name and number of hourly values\n",
    "for file_path in pm25_files:\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "            if data and isinstance(data, list):\n",
    "                station = data[0].get(\"station\", file_path.stem)\n",
    "                values = data[0].get(\"values\", [])\n",
    "                station_counts.append((station, len(values)))\n",
    "    except Exception as e:\n",
    "        print(f\" Error reading '{file_path.name}': {e}\")\n",
    "\n",
    "# Sort stations by number of values in descending order\n",
    "station_counts = sorted(station_counts, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the top 10 stations with the most PM2.5 values\n",
    "print(\" Top 10 stations with most hourly PM2.5 values:\\n\" + \"-\"*50)\n",
    "for station, count in station_counts[:10]:\n",
    "    print(f\"{station:<25} -> {count} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e16359-b233-4cfd-a7a9-50b890a26f60",
   "metadata": {},
   "source": [
    "#### Top 10 Stations by Hourly PM2.5 Records (2023)  \n",
    "*(EN) Stations with the highest number of hourly PM2.5 measurements.*  \n",
    "*(NO) Stasjoner med flest timesvise PM2.5-m√•linger.*  \n",
    "\n",
    "| Rank | Station            | Hourly Records |\n",
    "|------|--------------------|----------------|\n",
    "| 1    | Moheia Vest        | 8,731          |\n",
    "| 2    | Danmarks plass     | 8,725          |\n",
    "| 3    | Rolland, √Ösane     | 8,725          |\n",
    "| 4    | Furulund           | 8,724          |\n",
    "| 5    | Nedre Langgate     | 8,723          |\n",
    "| 6    | Knarrdalstranda    | 8,722          |\n",
    "| 7    | V√•land             | 8,722          |\n",
    "| 8    | R√•dal              | 8,721          |\n",
    "| 9    | Klosterhaugen      | 8,720          |\n",
    "| 10   | Sk√∏yen             | 8,719          |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8623fd9-c4b9-4f4e-9d94-9b866c087bb9",
   "metadata": {},
   "source": [
    "\n",
    "### Storing All PM2.5 Data in SQLite | Lagring av alle PM2.5-data i SQLite\n",
    "\n",
    "**(EN)** To simulate a scalable and structured data architecture, all downloaded JSON files containing PM2.5 measurements for 2023 were imported into a local SQLite database. Each station's data is saved as an individual table. This structure allows the use of SQL queries in future analyses, integration with other data sources (e.g., weather or GIS), or scalable pipelines for air quality monitoring.\n",
    "\n",
    "**(NO)** For √• simulere en skalerbar og strukturert datainfrastruktur, ble alle nedlastede JSON-filer med PM2.5-m√•linger for 2023 importert til en lokal SQLite-database. Dataene for hver stasjon er lagret som en egen tabell. Denne strukturen muliggj√∏r bruk av SQL-sp√∏rringer i fremtidige analyser, integrasjon med andre datakilder (f.eks. v√¶r eller GIS), eller skalerbare arbeidsflyter for luftkvalitetsoverv√•king.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e8e63d-8a83-4e0b-9940-d12de7cfbc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (EN) Save PM2.5 data from all stations to SQLite database\n",
    "# (NO) Lagring av alle PM2.5-data i SQLite fra alle stasjoner til SQLite-database\n",
    "\n",
    "# Paths previously defined in notebook\n",
    "DB_PATH = PROCESSED_DIR / \"pm25_2023.sqlite\"\n",
    "\n",
    "# Create SQLite connection\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "\n",
    "# List all PM2.5 JSON files\n",
    "json_files = sorted(RAW_DIR.glob(\"nilu_pm25_*.json\"))\n",
    "print(f\"Found {len(json_files)} PM2.5 files.\")\n",
    "\n",
    "# Loop through files, load into a pandas DataFrame, and save data to SQLite\n",
    "for file in json_files:\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    if data and isinstance(data, list) and isinstance(data[0], dict) and \"values\" in data[0]:\n",
    "        \n",
    "        # Sanitize station name for table naming\n",
    "        station = data[0].get(\"station\", file.stem).replace(\",\", \"\").replace(\" \", \"_\")\n",
    "        values = data[0][\"values\"]\n",
    "\n",
    "        # Load into a pandas DataFrame\n",
    "        df = pd.DataFrame(values)\n",
    "\n",
    "       # Add station-level metadata to each row\n",
    "        df[\"station\"] = station\n",
    "        df[\"component\"] = data[0].get(\"component\")\n",
    "        df[\"unit\"] = data[0].get(\"unit\")\n",
    "        df[\"timestep\"] = data[0].get(\"timestep\")\n",
    "\n",
    "        # Save to SQLite table\n",
    "        table_name = f\"pm25_{station.lower()}\"\n",
    "        df.to_sql(table_name, conn, if_exists=\"replace\", index=False)\n",
    "        print(f\"Table saved: {table_name}\")\n",
    "\n",
    "# Close connection\n",
    "conn.close()\n",
    "\n",
    "print(f\"SQLite database created at: {DB_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b44b312-cfdb-4927-bbd8-7f4b1fe7a863",
   "metadata": {},
   "source": [
    "**(EN) Result:** Created one SQLite table per station (58 tables) plus one aggregated table (`pm25_all`) from the PM2.5 JSON file. This structure supports modular data management while keeping a complete reference dataset for auditing or integration.  \n",
    "\n",
    "**(NO) Resultat:** Opprettet √©n SQLite-tabell per stasjon (58 tabeller) pluss √©n aggregert tabell (`pm25_all`) fra PM2.5-JSON-filen. Denne strukturen st√∏tter modul√¶r databehandling og gir et komplett referansedatasett for revisjon eller integrasjon.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3074cbd9-ab84-42e1-87ea-be6bd9007be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (EN) Load hourly PM2.5 data from the SQLite database\n",
    "# (NO) Last inn timesvise PM2.5-data fra SQLite-databasen\n",
    "\n",
    "with sqlite3.connect(DB_PATH) as conn:\n",
    "    sk√∏yen_df   = pd.read_sql(\"SELECT * FROM pm25_sk√∏yen\", conn)\n",
    "    furulund_df = pd.read_sql(\"SELECT * FROM pm25_furulund\", conn)\n",
    "\n",
    "# Show first rows to confirm\n",
    "display(sk√∏yen_df.head())\n",
    "display(furulund_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59714584-3985-4e51-b18e-e51a901da32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (EN) DB - Quality Assurance (QA): list all tables, then Top‚Äë10 stations by hourly PM2.5 values (with 2023 coverage %)\n",
    "# (NO) DB - Kvalitetssikring (KS): list opp alle tabeller, deretter Topp‚Äë10 stasjoner etter timesvise PM2.5‚Äëverdier (med dekning % for 2023)\n",
    "\n",
    "EXPECTED_HOURS = 8760  # 2023\n",
    "\n",
    "with sqlite3.connect(DB_PATH) as conn:\n",
    "    # 1) All tables (context)\n",
    "    all_tables = pd.read_sql(\"SELECT name FROM sqlite_master WHERE type='table' ORDER BY name;\", conn)\n",
    "    print(f\"Total tables in database: {len(all_tables)}\")\n",
    "    display(all_tables)\n",
    "\n",
    "    # 2) Per‚Äëstation PM2.5 tables\n",
    "    per_station = pd.read_sql(\"\"\"\n",
    "        SELECT name \n",
    "        FROM sqlite_master \n",
    "        WHERE type='table' AND name LIKE 'pm25_%'\n",
    "        ORDER BY name;\n",
    "    \"\"\", conn)\n",
    "    print(f\"\\nPer-station PM2.5 tables: {len(per_station)}\")\n",
    "    display(per_station.head(8))  # preview\n",
    "\n",
    "    # 3) Row counts per station + coverage %\n",
    "    counts = []\n",
    "    for tbl in per_station[\"name\"]:\n",
    "        n_rows = pd.read_sql(f'SELECT COUNT(*) AS rows FROM \"{tbl}\";', conn).iloc[0, 0]\n",
    "        station = tbl.replace(\"pm25_\", \"\", 1)\n",
    "        counts.append((station, n_rows))\n",
    "\n",
    "df_counts = (\n",
    "    pd.DataFrame(counts, columns=[\"Station\", \"Rows\"])\n",
    "    .assign(CoveragePct=lambda d: (d[\"Rows\"] / EXPECTED_HOURS * 100).round(1))\n",
    "    .sort_values([\"Rows\", \"Station\"], ascending=[False, True])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"\\nSQLite ‚Äî Top 10 stations by hourly PM2.5 values:\")\n",
    "display(df_counts.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d391ca83-24c5-409c-9b6e-054ebb587ba6",
   "metadata": {},
   "source": [
    "### SQLite Per-Station Tables Overview | Oversikt over SQLite-tabeller per stasjon\n",
    "\n",
    "**(EN)** The local SQLite database contains **58 tables**, each corresponding to a monitoring station. Below is a preview of the structure and row counts.\n",
    "\n",
    "**(NO)** Den lokale SQLite-databasen inneholder **58 tabeller**, √©n for hver m√•lestasjon. Nedenfor vises en forh√•ndsvisning av strukturen og antall rader.\n",
    "\n",
    "#### Table Preview \n",
    "\n",
    "| Table Name              | Rows  |\n",
    "|-------------------------|-------|\n",
    "| pm25_alnabru            | 8,420 |\n",
    "| pm25_alvim              | 8,352 |\n",
    "| pm25_backeparken        | 8,552 |\n",
    "| pm25_bankplassen        | 8,226 |\n",
    "| pm25_bekkestua          | 8,584 |\n",
    "| pm25_bj√∏rndalssletta    | 7,516 |\n",
    "| pm25_bryn_skole         | 60    |\n",
    "| pm25_brynbanen          | 7,680 |\n",
    "| pm25_bygd√∏y_alle        | 8,351 |\n",
    "| pm25_danmarks_plass     | 8,725 |\n",
    "\n",
    "\n",
    "#### Top 10 Stations by Hourly PM2.5 Coverage (2023)\n",
    "\n",
    "| Rank | Station           | Rows  | Coverage (%) |\n",
    "|------|--------------------|-------|---------------|\n",
    "| 1    | moheia_vest        | 8,731 | 99.7%         |\n",
    "| 2    | danmarks_plass     | 8,725 | 99.6%         |\n",
    "| 3    | rolland_√•sane      | 8,725 | 99.6%         |\n",
    "| 4    | furulund           | 8,724 | 99.6%         |\n",
    "| 5    | nedre_langgate     | 8,723 | 99.6%         |\n",
    "| 6    | knarrdalstranda    | 8,722 | 99.6%         |\n",
    "| 7    | v√•land             | 8,722 | 99.6%         |\n",
    "| 8    | r√•dal              | 8,721 | 99.6%         |\n",
    "| 9    | klosterhaugen      | 8,720 | 99.5%         |\n",
    "| 10   | sk√∏yen             | 8,719 | 99.5%         |\n",
    "\n",
    "_________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241d9a25-a264-4268-babe-07177bbd9ba7",
   "metadata": {},
   "source": [
    "### Selecting Stations for Analysis | Valg av m√•lestasjoner\n",
    "\n",
    "**(EN)** Based on the number of hourly PM2.5 records collected in 2023, two contrasting stations were selected for focused analysis:  **Sk√∏yen** (traffic-heavy, urban) and **Furulund** (quiet, residential), both located in **Oslo**.  \n",
    "These stations offer near-complete yearly coverage and represent distinct urban contexts, making them ideal for time-series modeling and anomaly detection.\n",
    "\n",
    "**(NO)** Basert p√• antall timesverdier for PM2.5 registrert i 2023, ble to kontrasterende stasjoner valgt for videre analyse:  **Sk√∏yen** (trafikkert, urbant) og **Furulund** (rolig, boligomr√•de), begge i **Oslo**.  \n",
    "Disse stasjonene har nesten full dekning og representerer ulike bymilj√∏er, noe som gir et godt grunnlag for tidsserieanalyse og avviksdeteksjon.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7541238d-c0c1-4e1e-acfe-7822e0a57270",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# (EN) Create an interactive bar chart of PM2.5 hourly records per station (2023)\n",
    "# (NO) Lag et interaktivt stolpediagram over PM2.5-timer per stasjon (2023)\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "# Create a DataFrame from the station_counts list\n",
    "df_counts = pd.DataFrame(station_counts, columns=[\"Station\", \"HourlyRecords\"])\n",
    "\n",
    "# Sort by number of records\n",
    "df_counts = df_counts.sort_values(by=\"HourlyRecords\", ascending=False)\n",
    "\n",
    "# Create interactive bar chart\n",
    "fig = px.bar(\n",
    "    df_counts,\n",
    "    x=\"Station\",\n",
    "    y=\"HourlyRecords\",\n",
    "    title=f\"PM2.5 Station Coverage - {YEAR}\",  \n",
    "    labels={\"HourlyRecords\": \"Number of Records\", \"Station\": \"Station\"},\n",
    "    hover_data={\"Station\": True, \"HourlyRecords\": True},\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_tickangle=45,\n",
    "    height=600,\n",
    "    margin=dict(t=60, b=100),\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Save figure\n",
    "fig.write_html(COVERAGE_HTML)\n",
    "fig.write_image(COVERAGE_PNG)\n",
    "\n",
    "print(\"Chart saved to:\")\n",
    "print(\" ‚Üí\", COVERAGE_HTML)\n",
    "print(\" ‚Üí\", COVERAGE_PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ddfbac-4fba-444d-bba4-45e163102e3f",
   "metadata": {},
   "source": [
    "**(EN)** Result: Chart `pm25_station_coverage_2023.html` and `pm25_station_coverage_2023.png` saved in `results/`  \n",
    "**(NO)** Resultat: Dekningsfigur lagret i `results/pm25_station_coverage_2023.html` og `PM2.5 pm25_station_coverage_2023.png`\n",
    "\n",
    "üìé üîó **[View interactive chart (HTML)](../results/pm25_station_coverage_2023.html?raw=1)**\n",
    "`\n"  
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4706394d-4720-4db3-8033-d6006e9e58bf",
   "metadata": {},
   "source": [
    "#### Data Collection and Structuring Completed | Datainnhenting og strukturering fullf√∏rt\n",
    "\n",
    "**EN:** Phase 1 is complete:\n",
    "- Fetched 2023 hourly PM2.5 from NILU for all available stations (Norway).\n",
    "- Inspected per‚Äëstation coverage.\n",
    "- Selected two Oslo stations (Sk√∏yen, Furulund) for deeper analysis.\n",
    "- Persisted raw/structured data to SQLite for scalable querying and reuse.\n",
    "\n",
    "**NO:** F√∏rste fase er fullf√∏rt:\n",
    "- Hentet timesvise PM2.5‚Äëdata (2023) fra NILU for alle tilgjengelige stasjoner.\n",
    "- Inspiserte datadekning per stasjon.\n",
    "- Valgte to Oslo-stasjoner (Sk√∏yen, Furulund) for videre analyser.\n",
    "- Lagret r√•/strukturerte data i SQLite for skalerbare sp√∏rringer og gjenbruk.\n",
    "\n",
    "_____\n",
    "\n",
    "#### Next Step | Neste steg\n",
    "Proceed to Notebook 2 for exploratory analysis and quality checks.\n",
    "\n",
    "_____\n",
    "\n",
    "**Navigation Links**\n",
    "  \n",
    "- [Notebook 2 ‚Äì Exploratory Analysis and Quality Checks](./02_exploratory_qc.ipynb)  \n",
    "- [Notebook 3 ‚Äì Feature Engineering and Anomaly Detection](./03_features_anomalies.ipynb)  \n",
    "- [Notebook 4 ‚Äì Summary Report (EN)](./04_report.ipynb)  \n",
    "- [Notebook 5 ‚Äì Sammendragsrapport (NO)](./05_report_norsk.ipynb) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c513d380-f4da-4b6a-8586-3b5e19d18d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (EN) Notebook 1 complete\n",
    "# (NO) Notebook 1 ferdig\n",
    "\n",
    "print(\"Notebook 1 complete ‚Äî data collected and structured into SQLite (pm25_2023.sqlite), ready for Notebook 2 (Exploratory Analysis and Quality Checks).\")\n",
    "print(\"Notebook 1 ferdig ‚Äî data samlet inn og strukturert i SQLite (pm25_2023.sqlite), klar for Notebook 2 (Utforskende analyse og kvalitetskontroll).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
